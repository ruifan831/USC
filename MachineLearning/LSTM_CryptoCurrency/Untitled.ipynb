{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BCH-USD.csv', 'BTC-USD.csv', 'ETH-USD.csv', 'LTC-USD.csv']\n",
      "73152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "SEQ_LEN=60\n",
    "FUTURE_PERIOD_PREDICT=3\n",
    "RATIO_TO_PREDICT='LTC-USD'\n",
    "data_files=os.listdir('crypto_data')\n",
    "columns_name=['time','low','high','open','close','volume']\n",
    "print(data_files)\n",
    "df=pd.read_csv('crypto_data/LTC-USD.csv',names=columns_name)\n",
    "\n",
    "\n",
    "def classify(current,future):\n",
    "    if float(future)> float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future',1)\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col]=df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col]= preprocessing.scale(df[col].values)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sequential_data=[]\n",
    "    prev_days=deque(maxlen=SEQ_LEN)\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days)==SEQ_LEN:\n",
    "            sequential_data.append((prev_days,i[-1]))\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    buys=[]\n",
    "    sells=[]\n",
    "\n",
    "    for seq,target in sequential_data:\n",
    "        if target==0:\n",
    "            sells.append([seq,target])\n",
    "        elif target==1:\n",
    "            buys.append([seq,target])\n",
    "    lower = min(len(buys),len(sells))\n",
    "\n",
    "    buys= buys[:lower]\n",
    "    sells=sells[:lower]\n",
    "\n",
    "    sequential_data=buys + sells\n",
    "    random.shuffle(sequential_data)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for seq,target in sequential_data:\n",
    "        X.append(seq)\n",
    "        Y.append(target)\n",
    "    return np.array(X),np.array(Y)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main_df=pd.DataFrame()\n",
    "for i in data_files:\n",
    "    dataset=f'crypto_data/{i}'\n",
    "    coin=i.split('.')[0]\n",
    "    df=pd.read_csv(dataset,names=columns_name)\n",
    "    df.rename(columns={'close':f'{coin}_close','volume':f'{coin}_volume'},inplace=True)\n",
    "\n",
    "    df.set_index('time',inplace=True)\n",
    "    df=df[[f'{coin}_close',f'{coin}_volume']]\n",
    "    if len(main_df)==0:\n",
    "        main_df=df\n",
    "    else:\n",
    "        main_df=main_df.join(df)\n",
    "\n",
    "main_df['future']=main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "\n",
    "main_df['target']=list(map(classify,main_df[f\"{RATIO_TO_PREDICT}_close\"],main_df['future']))\n",
    "\n",
    "times = sorted(main_df.index.values)\n",
    "last_5pct= times[-int(0.05*len(times))]\n",
    "\n",
    "validation_main_df=main_df[(main_df.index>= last_5pct)]\n",
    "main_df=main_df[(main_df<last_5pct)]\n",
    "\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "val_x, val_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(len(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM,CuDNNLSTM,BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "BATCH_SIZE=64\n",
    "\n",
    "NAME=f'{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}'\n",
    "data_files=os.listdir('crypto_data')\n",
    "model=Sequential()\n",
    "model.add(CuDNNLSTM(128,input_shape=(train_x.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128,input_shape=(train_x.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128,input_shape=(train_x.shape[1:])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "tensorboard=TensorBoard(log_dir=f'logs/{NAME}')\n",
    "\n",
    "filepath='RNN_Final-{epoch:02d}'\n",
    "\n",
    "checkpoint = ModelCheckpoint('models/{}.model'.format(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 60, 128)           70656     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 60, 128)           512       \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 60, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 60, 128)           512       \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 340,578\n",
      "Trainable params: 339,810\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73152 samples, validate on 3688 samples\n",
      "Epoch 1/10\n",
      "73152/73152 [==============================] - 23s 320us/sample - loss: 0.6939 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "73152/73152 [==============================] - 23s 312us/sample - loss: 0.6933 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "73152/73152 [==============================] - 22s 306us/sample - loss: 0.6933 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "73152/73152 [==============================] - 23s 309us/sample - loss: 0.6933 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "73152/73152 [==============================] - 23s 313us/sample - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "73152/73152 [==============================] - 23s 308us/sample - loss: 0.6933 - acc: 0.5028 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "73152/73152 [==============================] - 23s 310us/sample - loss: 0.6934 - acc: 0.4979 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "73152/73152 [==============================] - 23s 310us/sample - loss: 0.6932 - acc: 0.4940 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "73152/73152 [==============================] - 23s 309us/sample - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "73152/73152 [==============================] - 23s 309us/sample - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_x,train_y,batch_size= BATCH_SIZE, epochs=EPOCHS, validation_data=(val_x,val_y),callbacks=[tensorboard,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73152, 60, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
