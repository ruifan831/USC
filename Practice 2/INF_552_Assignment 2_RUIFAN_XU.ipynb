{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "df = pd.read_excel(\"Folds5x2_pp.xlsx\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b i\n",
    "print(\"How many rows are in this data set?\",df.shape[0])\n",
    "print(\"How many columns?\",df.shape[1])\n",
    "print(\"What do the rows and columns represent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop(\"PE\",1)\n",
    "y=df[\"PE\"]\n",
    "for i in df1.columns.tolist():\n",
    "    plt.plot(df[i],y,'bo')\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel(\"PE\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_table=df.describe(include='all')\n",
    "ranges=[]\n",
    "inters=[]\n",
    "for i in summarize_table.columns.tolist():\n",
    "    range_i = summarize_table[i].at[\"max\"]-summarize_table[i].at[\"min\"]\n",
    "    ranges.append(range_i)\n",
    "    inter= summarize_table[i].at[\"75%\"]-summarize_table[i].at[\"25%\"]\n",
    "    inters.append(inter)\n",
    "new_rows=[ranges,inters]\n",
    "new_rows=pd.DataFrame(new_rows,columns=[\"AT\",\"V\",\"AP\",\"RH\",\"PE\"])\n",
    "summarize_table=pd.concat([summarize_table,new_rows],axis=0)\n",
    "summarize_table = summarize_table.reset_index()\n",
    "summarize_table.iloc[[8,9],0] = ['range', 'inters']\n",
    "summarize_table = summarize_table.set_index('index')\n",
    "display(summarize_table)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "df1=df.drop(\"PE\",1)\n",
    "y=df[\"PE\"]\n",
    "\n",
    "par_coe=[]\n",
    "col_index=df1.columns.tolist()\n",
    "lor=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(features,label):\n",
    "    X = sm.add_constant(features)\n",
    "    est = sm.OLS(label, X).fit()\n",
    "    pre=est.predict(X.values)\n",
    "    result = pd.DataFrame(est.summary2().tables[1])\n",
    "    insig_features=result.index[result['P>|t|']>=0.05].tolist()\n",
    "    sig_features=result.index[result['P>|t|']<=0.05].tolist()\n",
    "    insig_features=[i for i in insig_features if i not in ['AT','V','AP','RH']]\n",
    "    coef=est.params[1:]\n",
    "    r_sqr=float(est.summary2().tables[0].iloc[6,1])\n",
    "    return pre,sig_features,coef,insig_features,est,r_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col_index:\n",
    "    print(i)\n",
    "    features= df1[i]\n",
    "    pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(features,y)\n",
    "    for i in sig_features:\n",
    "        para=est.params.get(i)\n",
    "        print(i+\": \" +str(round(para,4))+ \" is statistically significant at 5% significance level\")\n",
    "    print(est.summary())\n",
    "    lor.append(r_sqr)\n",
    "    par_coe.extend(coef.values)\n",
    "    plt.plot(df1[i],y,\"ro\",label=\"Scatter plot\")\n",
    "    plt.plot(df1[i], pred, \"b-\",label=\"Fitted Line\")\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel(\"PE\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('----------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(df1,y)\n",
    "print(est.summary())\n",
    "coef_d=coef\n",
    "for i in sig_features:\n",
    "        para=est.params.get(i)\n",
    "        print(i+\": \" +str(round(para,4))+ \" is statistically significant at 5% significance level\")\n",
    "lor.append(r_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E\n",
    "list1 = par_coe\n",
    "list2 = coef_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list1,list2,\"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F\n",
    "for i in col_index:\n",
    "    X = df1[i]\n",
    "    X_pro = pd.DataFrame(np.column_stack((X, X**2,X**3)),columns=[i,i+'**2',i+'**3'])\n",
    "    pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(X_pro,y)\n",
    "    print(est.summary())\n",
    "    for i in sig_features:\n",
    "        para=est.params.get(i)\n",
    "        print(i+\": \" +str(round(para,4))+ \" is statistically significant at 5% significance level\")\n",
    "    pred=pd.DataFrame(pred)\n",
    "    X=pd.concat([X,pred],axis=1)\n",
    "    lor.append(r_sqr)\n",
    "    print(\"------------------------\")\n",
    "    print(\"next\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "X_new = poly.fit_transform(df1)\n",
    "X_new=pd.DataFrame(X_new)\n",
    "X_new.columns = ['AT','V','AP','RH','AT*V','AT*AP','AT*RH','V*AP','V*RH','AP*RH']\n",
    "pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(X_new,y)\n",
    "print(est.summary())\n",
    "for i in sig_features:\n",
    "        para=est.params.get(i)\n",
    "        print(i+\": \" +str(round(para,4))+ \" is statistically significant at 5% significance level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h\n",
    "# Model with all predictors\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, y, test_size=0.30)\n",
    "pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(X_train,y_train)\n",
    "print(est.summary())\n",
    "lor.append(r_sqr)\n",
    "X_test = sm.add_constant(X_test)\n",
    "y_test_pre=est.predict(X_test)\n",
    "MSE_tr = (sum((y_train-pred)**2))/(X_train.shape[0]-X_train.shape[1]-1)\n",
    "MSE_te = (sum((y_test-y_test_pre)**2))/(X_test.shape[0]-X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model with all predictors, Trainning MSE: \",MSE_tr)\n",
    "print(\"Model with all predictors, Test MSE: \",MSE_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Modle with all possible interaction terms and quadratic nonlinearities\n",
    "df_h= PolynomialFeatures(interaction_only=False, include_bias=False).fit_transform(df1,y)\n",
    "df_h=pd.DataFrame(df_h)\n",
    "df_h.columns=['AT','V','AP','RH','AT**2','AT*V','AT*AP','AT*RH','V**2','V*AP','V*RH','AP**2','AP*RH','RH**2']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_h, y, test_size=0.30)\n",
    "pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(X_train,y_train)\n",
    "while insig_features:\n",
    "    X_train = X_train.drop(insig_features,axis=1)\n",
    "    X_test = X_test.drop(insig_features,axis=1)\n",
    "    pred, sig_features,coef,insig_features,est,r_sqr=linear_reg(X_train,y_train)\n",
    "for i in sig_features:\n",
    "        para=est.params.get(i)\n",
    "        print(i+\": \" +str(round(para,4))+ \" is statistically significant at 5% significance level\")\n",
    "lor.append(r_sqr)\n",
    "selected_fea=pd.DataFrame(est.summary2().tables[1]).index.tolist()\n",
    "X_test = sm.add_constant(X_test)\n",
    "X_test=X_test[selected_fea]\n",
    "y_test_pre=est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_tr = (sum((y_train-pred)**2))/(X_train.shape[0]-X_train.shape[1]-1)\n",
    "MSE_te = (sum((y_test-y_test_pre)**2))/(X_test.shape[0]-X_test.shape[1])\n",
    "print(\"MSE TRAINING: \",MSE_tr)\n",
    "print(\"MSE TEST: \", MSE_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i\n",
    "def knn_reg(data,label):\n",
    "    X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(data, label, test_size=0.30)\n",
    "    min_err=1\n",
    "    opt_k=1\n",
    "    tr_errors=[]\n",
    "    te_errors=[]\n",
    "    k_size=np.arange(1,101,1)\n",
    "    for i in k_size:\n",
    "        knn=KNeighborsRegressor(n_neighbors=i)\n",
    "        knn.fit(X_train_i,y_train_i)\n",
    "        tr_error=1-knn.score(X_train_i,y_train_i)\n",
    "        te_error=1-knn.score(X_test_i,y_test_i)\n",
    "        tr_errors.append(tr_error)\n",
    "        te_errors.append(te_error)\n",
    "        if te_error <= min_err:\n",
    "            min_err=te_error\n",
    "            opt_k=i\n",
    "    return k_size, tr_errors,te_errors,opt_k,min_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "k_size, tr_errors,te_errors,opt_k,min_err1=knn_reg(df1,y)\n",
    "k_size=[i/100 for i in k_size]\n",
    "plt.plot(k_size, tr_errors, \"r-\", label=\"Train Error Rate\")\n",
    "plt.plot(k_size, te_errors, \"b-\", label=\"Test Error Rate\")\n",
    "plt.xlabel(\"K size\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(opt_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized Data\n",
    "df_nor=scale(df1)\n",
    "k_size, tr_errors,te_errors,opt_k,min_err2=knn_reg(df_nor,y)\n",
    "k_size=[i/100 for i in k_size]\n",
    "plt.plot(k_size, tr_errors, \"r-\", label=\"Train Error Rate\")\n",
    "plt.plot(k_size, te_errors, \"b-\", label=\"Test Error Rate\")\n",
    "plt.xlabel(\"K size\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(opt_k)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_err=1-max(lor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_err1 < min_err2:\n",
    "    if min_err1< lin_err:\n",
    "        print(\"Min_err1: \", min_err1)\n",
    "    else:\n",
    "        print(\"Linear regression error: \", lin_err)\n",
    "else:\n",
    "    if min_err2<lin_err:\n",
    "        print(\"Min_err1: \", min_err2)\n",
    "    else:\n",
    "        print(\"Linear regression error: \", lin_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    RUIFAN XU\n",
    "    USC ID: 1995124351\n",
    "           \n",
    "    1:\n",
    "    \n",
    "          AT      V       AP     RH      PE\n",
    "    0  14.96  41.76  1024.07  73.17  463.26\n",
    "    1  25.18  62.96  1020.04  59.08  444.37\n",
    "    2   5.11  39.40  1012.16  92.14  488.56\n",
    "    3  20.86  57.32  1010.24  76.64  446.48\n",
    "    4  10.82  37.50  1009.23  96.62  473.90\n",
    "\n",
    "    b)\n",
    "        i:\n",
    "        How many rows are in this data set? 9568\n",
    "        How many columns? 5\n",
    "        What do the rows and columns represent? \n",
    "            Colunmns represent the features that each data has.\n",
    "            Rows represent each data in the data set.\n",
    "\n",
    "\n",
    "\n",
    "        ii:Make pairwise scatterplots of all the varianbles in the data set including the \n",
    "        predictors (independent variables) with the dependent variable.\n",
    "        \n",
    "![png](output_3_0.png)\n",
    "        \n",
    "        AT may has a negative effect on PE.\n",
    "     \n",
    "![png](output_3_1.png)\n",
    "        \n",
    "        V may has a negative effect on PE.\n",
    "\n",
    "\n",
    "![png](output_3_2.png)\n",
    "\n",
    "        AP may has a positive effect on PE.\n",
    "\n",
    "![png](output_3_3.png)\n",
    "\n",
    "        RH may has a positive effect on PE.\n",
    "\n",
    "\n",
    "        iii: The mean, the median, range, first and third quartiles, and in-terquartile ranges of each of the variables in the dataset.\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>AT</th>\n",
    "      <th>V</th>\n",
    "      <th>AP</th>\n",
    "      <th>RH</th>\n",
    "      <th>PE</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>index</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>count</th>\n",
    "      <td>9568.000000</td>\n",
    "      <td>9568.000000</td>\n",
    "      <td>9568.000000</td>\n",
    "      <td>9568.000000</td>\n",
    "      <td>9568.000000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>mean</th>\n",
    "      <td>19.651231</td>\n",
    "      <td>54.305804</td>\n",
    "      <td>1013.259078</td>\n",
    "      <td>73.308978</td>\n",
    "      <td>454.365009</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>std</th>\n",
    "      <td>7.452473</td>\n",
    "      <td>12.707893</td>\n",
    "      <td>5.938784</td>\n",
    "      <td>14.600269</td>\n",
    "      <td>17.066995</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>min</th>\n",
    "      <td>1.810000</td>\n",
    "      <td>25.360000</td>\n",
    "      <td>992.890000</td>\n",
    "      <td>25.560000</td>\n",
    "      <td>420.260000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>25%</th>\n",
    "      <td>13.510000</td>\n",
    "      <td>41.740000</td>\n",
    "      <td>1009.100000</td>\n",
    "      <td>63.327500</td>\n",
    "      <td>439.750000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>50%</th>\n",
    "      <td>20.345000</td>\n",
    "      <td>52.080000</td>\n",
    "      <td>1012.940000</td>\n",
    "      <td>74.975000</td>\n",
    "      <td>451.550000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>75%</th>\n",
    "      <td>25.720000</td>\n",
    "      <td>66.540000</td>\n",
    "      <td>1017.260000</td>\n",
    "      <td>84.830000</td>\n",
    "      <td>468.430000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>max</th>\n",
    "      <td>37.110000</td>\n",
    "      <td>81.560000</td>\n",
    "      <td>1033.300000</td>\n",
    "      <td>100.160000</td>\n",
    "      <td>495.760000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>range</th>\n",
    "      <td>35.300000</td>\n",
    "      <td>56.200000</td>\n",
    "      <td>40.410000</td>\n",
    "      <td>74.600000</td>\n",
    "      <td>75.500000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>inters</th>\n",
    "      <td>12.210000</td>\n",
    "      <td>24.800000</td>\n",
    "      <td>8.160000</td>\n",
    "      <td>21.502500</td>\n",
    "      <td>28.680000</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "    c)\n",
    "    \n",
    "    AT\n",
    "    const: 497.0341 is statistically significant at 5% significance level\n",
    "    AT: -2.1713 is statistically significant at 5% significance level\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.899\n",
    "    Model:                            OLS   Adj. R-squared:                  0.899\n",
    "    Method:                 Least Squares   F-statistic:                 8.510e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:49:18   Log-Likelihood:                -29756.\n",
    "    No. Observations:                9568   AIC:                         5.952e+04\n",
    "    Df Residuals:                    9566   BIC:                         5.953e+04\n",
    "    Df Model:                           1                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        497.0341      0.156   3177.280      0.000     496.727     497.341\n",
    "    AT            -2.1713      0.007   -291.715      0.000      -2.186      -2.157\n",
    "    ==============================================================================\n",
    "    Omnibus:                      417.457   Durbin-Watson:                   2.033\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1117.844\n",
    "    Skew:                          -0.209   Prob(JB):                    1.83e-243\n",
    "    Kurtosis:                       4.621   Cond. No.                         59.4\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "\n",
    "\n",
    "![png](output_7_1.png)\n",
    "\n",
    "\n",
    "    ----------------------------------\n",
    "    V\n",
    "    const: 517.8015 is statistically significant at 5% significance level\n",
    "    V: -1.1681 is statistically significant at 5% significance level\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.757\n",
    "    Model:                            OLS   Adj. R-squared:                  0.756\n",
    "    Method:                 Least Squares   F-statistic:                 2.972e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:49:18   Log-Likelihood:                -33963.\n",
    "    No. Observations:                9568   AIC:                         6.793e+04\n",
    "    Df Residuals:                    9566   BIC:                         6.794e+04\n",
    "    Df Model:                           1                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        517.8015      0.378   1370.218      0.000     517.061     518.542\n",
    "    V             -1.1681      0.007   -172.402      0.000      -1.181      -1.155\n",
    "    ==============================================================================\n",
    "    Omnibus:                       77.693   Durbin-Watson:                   2.007\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              109.571\n",
    "    Skew:                          -0.097   Prob(JB):                     1.61e-24\n",
    "    Kurtosis:                       3.487   Cond. No.                         245.\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "\n",
    "\n",
    "![png](output_7_3.png)\n",
    "\n",
    "\n",
    "    ----------------------------------\n",
    "    AP\n",
    "    const: -1055.261 is statistically significant at 5% significance level\n",
    "    AP: 1.4899 is statistically significant at 5% significance level\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.269\n",
    "    Model:                            OLS   Adj. R-squared:                  0.269\n",
    "    Method:                 Least Squares   F-statistic:                     3516.\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:49:18   Log-Likelihood:                -39224.\n",
    "    No. Observations:                9568   AIC:                         7.845e+04\n",
    "    Df Residuals:                    9566   BIC:                         7.847e+04\n",
    "    Df Model:                           1                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const      -1055.2610     25.459    -41.449      0.000   -1105.167   -1005.355\n",
    "    AP             1.4899      0.025     59.296      0.000       1.441       1.539\n",
    "    ==============================================================================\n",
    "    Omnibus:                      525.438   Durbin-Watson:                   1.996\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.290\n",
    "    Skew:                           0.616   Prob(JB):                    1.10e-133\n",
    "    Kurtosis:                       2.859   Cond. No.                     1.73e+05\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 1.73e+05. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "\n",
    "\n",
    "\n",
    "![png](output_7_5.png)\n",
    "\n",
    "\n",
    "    ----------------------------------\n",
    "    RH\n",
    "    const: 420.9618 is statistically significant at 5% significance level\n",
    "    RH: 0.4557 is statistically significant at 5% significance level\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.152\n",
    "    Model:                            OLS   Adj. R-squared:                  0.152\n",
    "    Method:                 Least Squares   F-statistic:                     1714.\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:49:19   Log-Likelihood:                -39933.\n",
    "    No. Observations:                9568   AIC:                         7.987e+04\n",
    "    Df Residuals:                    9566   BIC:                         7.988e+04\n",
    "    Df Model:                           1                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        420.9618      0.823    511.676      0.000     419.349     422.574\n",
    "    RH             0.4557      0.011     41.399      0.000       0.434       0.477\n",
    "    ==============================================================================\n",
    "    Omnibus:                      772.278   Durbin-Watson:                   1.998\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              319.245\n",
    "    Skew:                           0.231   Prob(JB):                     4.75e-70\n",
    "    Kurtosis:                       2.234   Cond. No.                         383.\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    \n",
    "    \n",
    "![png](output_7_7.png)\n",
    "\n",
    "\n",
    "    In each simple linear regression model, we do have several outliers would like to remove from the data.\n",
    "\n",
    "    d)\n",
    "\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.929\n",
    "    Model:                            OLS   Adj. R-squared:                  0.929\n",
    "    Method:                 Least Squares   F-statistic:                 3.114e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:49:23   Log-Likelihood:                -28088.\n",
    "    No. Observations:                9568   AIC:                         5.619e+04\n",
    "    Df Residuals:                    9563   BIC:                         5.622e+04\n",
    "    Df Model:                           4                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        454.6093      9.749     46.634      0.000     435.500     473.718\n",
    "    AT            -1.9775      0.015   -129.342      0.000      -2.007      -1.948\n",
    "    V             -0.2339      0.007    -32.122      0.000      -0.248      -0.220\n",
    "    AP             0.0621      0.009      6.564      0.000       0.044       0.081\n",
    "    RH            -0.1581      0.004    -37.918      0.000      -0.166      -0.150\n",
    "    ==============================================================================\n",
    "    Omnibus:                      892.002   Durbin-Watson:                   2.033\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4086.777\n",
    "    Skew:                          -0.352   Prob(JB):                         0.00\n",
    "    Kurtosis:                       6.123   Cond. No.                     2.13e+05\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 2.13e+05. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    const: 454.6093 is statistically significant at 5% significance level\n",
    "    AT: -1.9775 is statistically significant at 5% significance level\n",
    "    V: -0.2339 is statistically significant at 5% significance level\n",
    "    AP: 0.0621 is statistically significant at 5% significance level\n",
    "    RH: -0.1581 is statistically significant at 5% significance level\n",
    "\n",
    "\n",
    "    e)How do your results from 1c compare to your results from 1d?\n",
    "    By fitting a multiple regression, the coeffecient of each features have changed by comparing their coeffiecents in simple regression model. This can be the result of having correlation between each feature.\n",
    "\n",
    "\n",
    "![png](output_10_0.png)\n",
    "\n",
    "\n",
    "    f) Is there evidence of nonlinear association between any of the predictors and the response?\n",
    "    \n",
    "    AT:\n",
    "\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.912\n",
    "    Model:                            OLS   Adj. R-squared:                  0.912\n",
    "    Method:                 Least Squares   F-statistic:                 3.299e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:50:45   Log-Likelihood:                -29101.\n",
    "    No. Observations:                9568   AIC:                         5.821e+04\n",
    "    Df Residuals:                    9564   BIC:                         5.824e+04\n",
    "    Df Model:                           3                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        492.7281      0.673    732.248      0.000     491.409     494.047\n",
    "    AT            -0.6103      0.124     -4.941      0.000      -0.852      -0.368\n",
    "    AT**2         -0.1251      0.007    -18.199      0.000      -0.139      -0.112\n",
    "    AT**3          0.0027      0.000     22.594      0.000       0.002       0.003\n",
    "    ==============================================================================\n",
    "    Omnibus:                      648.041   Durbin-Watson:                   2.033\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2767.059\n",
    "    Skew:                          -0.191   Prob(JB):                         0.00\n",
    "    Kurtosis:                       5.607   Cond. No.                     1.90e+05\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 1.9e+05. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    \n",
    "    const: 492.7281 is statistically significant at 5% significance level\n",
    "    AT: -0.6103 is statistically significant at 5% significance level\n",
    "    AT**2: -0.1251 is statistically significant at 5% significance level\n",
    "    AT**3: 0.0027 is statistically significant at 5% significance level\n",
    "    ------------------------\n",
    "    \n",
    "    V:\n",
    "    \n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.775\n",
    "    Model:                            OLS   Adj. R-squared:                  0.775\n",
    "    Method:                 Least Squares   F-statistic:                 1.098e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:50:46   Log-Likelihood:                -33585.\n",
    "    No. Observations:                9568   AIC:                         6.718e+04\n",
    "    Df Residuals:                    9564   BIC:                         6.721e+04\n",
    "    Df Model:                           3                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        554.1468      9.151     60.557      0.000     536.209     572.084\n",
    "    V             -2.1444      0.509     -4.214      0.000      -3.142      -1.147\n",
    "    V**2          -0.0027      0.009     -0.294      0.768      -0.021       0.015\n",
    "    V**3           0.0001   5.45e-05      2.465      0.014    2.75e-05       0.000\n",
    "    ==============================================================================\n",
    "    Omnibus:                      160.101   Durbin-Watson:                   2.009\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              279.778\n",
    "    Skew:                          -0.125   Prob(JB):                     1.77e-61\n",
    "    Kurtosis:                       3.800   Cond. No.                     2.47e+07\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 2.47e+07. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    \n",
    "    const: 554.1468 is statistically significant at 5% significance level\n",
    "    V: -2.1444 is statistically significant at 5% significance level\n",
    "    V**3: 0.0001 is statistically significant at 5% significance level\n",
    "    ------------------------\n",
    "    \n",
    "    \n",
    "    AP:\n",
    "    \n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.275\n",
    "    Model:                            OLS   Adj. R-squared:                  0.275\n",
    "    Method:                 Least Squares   F-statistic:                     1813.\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:50:46   Log-Likelihood:                -39184.\n",
    "    No. Observations:                9568   AIC:                         7.837e+04\n",
    "    Df Residuals:                    9565   BIC:                         7.840e+04\n",
    "    Df Model:                           2                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const          0.0747      0.009      8.415      0.000       0.057       0.092\n",
    "    AP            25.2556      3.001      8.415      0.000      19.372      31.139\n",
    "    AP**2         -0.0500      0.006     -8.439      0.000      -0.062      -0.038\n",
    "    AP**3       2.514e-05   2.92e-06      8.613      0.000    1.94e-05    3.09e-05\n",
    "    ==============================================================================\n",
    "    Omnibus:                      556.766   Durbin-Watson:                   1.997\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              640.319\n",
    "    Skew:                           0.621   Prob(JB):                    9.05e-140\n",
    "    Kurtosis:                       2.751   Cond. No.                     2.12e+15\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 2.12e+15. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    \n",
    "    const: 0.0747 is statistically significant at 5% significance level\n",
    "    AP: 25.2556 is statistically significant at 5% significance level\n",
    "    AP**2: -0.05 is statistically significant at 5% significance level\n",
    "    AP**3: 0.0 is statistically significant at 5% significance level\n",
    "    ------------------------\n",
    "    RH:\n",
    "    \n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.154\n",
    "    Model:                            OLS   Adj. R-squared:                  0.153\n",
    "    Method:                 Least Squares   F-statistic:                     579.2\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:50:46   Log-Likelihood:                -39923.\n",
    "    No. Observations:                9568   AIC:                         7.985e+04\n",
    "    Df Residuals:                    9564   BIC:                         7.988e+04\n",
    "    Df Model:                           3                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        468.4135     10.545     44.422      0.000     447.744     489.083\n",
    "    RH            -1.7292      0.486     -3.557      0.000      -2.682      -0.776\n",
    "    RH**2          0.0321      0.007      4.433      0.000       0.018       0.046\n",
    "    RH**3         -0.0002   3.51e-05     -4.340      0.000      -0.000   -8.34e-05\n",
    "    ==============================================================================\n",
    "    Omnibus:                      707.867   Durbin-Watson:                   1.998\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              302.057\n",
    "    Skew:                           0.223   Prob(JB):                     2.56e-66\n",
    "    Kurtosis:                       2.253   Cond. No.                     3.26e+07\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 3.26e+07. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    \n",
    "    const: 468.4135 is statistically significant at 5% significance level\n",
    "    RH: -1.7292 is statistically significant at 5% significance level\n",
    "    RH**2: 0.0321 is statistically significant at 5% significance level\n",
    "    RH**3: -0.0002 is statistically significant at 5% significance level\n",
    "\n",
    "\n",
    "    ------------------------\n",
    "    \n",
    "    g) Is there evidence of association of interactions of predictors with the response?\n",
    "\n",
    "\n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.936\n",
    "    Model:                            OLS   Adj. R-squared:                  0.936\n",
    "    Method:                 Least Squares   F-statistic:                 1.405e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:51:12   Log-Likelihood:                -27548.\n",
    "    No. Observations:                9568   AIC:                         5.512e+04\n",
    "    Df Residuals:                    9557   BIC:                         5.520e+04\n",
    "    Df Model:                          10                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        685.7825     78.640      8.721      0.000     531.631     839.934\n",
    "    AT            -4.3470      2.373     -1.832      0.067      -8.999       0.305\n",
    "    V             -7.6749      1.351     -5.682      0.000     -10.323      -5.027\n",
    "    AP            -0.1524      0.077     -1.983      0.047      -0.303      -0.002\n",
    "    RH             1.5709      0.773      2.031      0.042       0.055       3.087\n",
    "    AT*V           0.0210      0.001     23.338      0.000       0.019       0.023\n",
    "    AT*AP          0.0018      0.002      0.752      0.452      -0.003       0.006\n",
    "    AT*RH         -0.0052      0.001     -6.444      0.000      -0.007      -0.004\n",
    "    V*AP           0.0068      0.001      5.135      0.000       0.004       0.009\n",
    "    V*RH           0.0008      0.000      1.716      0.086      -0.000       0.002\n",
    "    AP*RH         -0.0016      0.001     -2.125      0.034      -0.003      -0.000\n",
    "    ==============================================================================\n",
    "    Omnibus:                     1454.609   Durbin-Watson:                   2.030\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9170.848\n",
    "    Skew:                          -0.574   Prob(JB):                         0.00\n",
    "    Kurtosis:                       7.657   Cond. No.                     1.70e+08\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 1.7e+08. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    const: 685.7825 is statistically significant at 5% significance level\n",
    "    V: -7.6749 is statistically significant at 5% significance level\n",
    "    AP: -0.1524 is statistically significant at 5% significance level\n",
    "    RH: 1.5709 is statistically significant at 5% significance level\n",
    "    AT*V: 0.021 is statistically significant at 5% significance level\n",
    "    AT*RH: -0.0052 is statistically significant at 5% significance level\n",
    "    V*AP: 0.0068 is statistically significant at 5% significance level\n",
    "    AP*RH: -0.0016 is statistically significant at 5% significance level\n",
    "\n",
    "    \n",
    "    There are evidences of association of interactions of predictors with the response.\n",
    "    \n",
    "    h) Can you improve your model using possible interaction terms or nonlinear asso-\n",
    "    ciations between the predictors and response?\n",
    "    \n",
    "    # Model with all predictors\n",
    "    \n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.927\n",
    "    Model:                            OLS   Adj. R-squared:                  0.927\n",
    "    Method:                 Least Squares   F-statistic:                 2.130e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:51:37   Log-Likelihood:                -19719.\n",
    "    No. Observations:                6697   AIC:                         3.945e+04\n",
    "    Df Residuals:                    6692   BIC:                         3.948e+04\n",
    "    Df Model:                           4                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const        447.5256     11.702     38.245      0.000     424.587     470.465\n",
    "    AT            -1.9692      0.019   -105.660      0.000      -2.006      -1.933\n",
    "    V             -0.2314      0.009    -26.163      0.000      -0.249      -0.214\n",
    "    AP             0.0686      0.011      6.038      0.000       0.046       0.091\n",
    "    RH            -0.1556      0.005    -30.927      0.000      -0.165      -0.146\n",
    "    ==============================================================================\n",
    "    Omnibus:                      650.741   Durbin-Watson:                   2.003\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2794.477\n",
    "    Skew:                          -0.398   Prob(JB):                         0.00\n",
    "    Kurtosis:                       6.063   Cond. No.                     2.12e+05\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 2.12e+05. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "    \n",
    "    Model with all predictors, Trainning MSE:  21.151982880374938\n",
    "    Model with all predictors, Test MSE:  19.964475413114787\n",
    "    \n",
    "    \n",
    "    ---------------------\n",
    "    Regression Modle with all possible interaction terms and quadratic nonlinearities\n",
    "    \n",
    "    \n",
    "                                OLS Regression Results                            \n",
    "    ==============================================================================\n",
    "    Dep. Variable:                     PE   R-squared:                       0.939\n",
    "    Model:                            OLS   Adj. R-squared:                  0.939\n",
    "    Method:                 Least Squares   F-statistic:                 1.023e+04\n",
    "    Date:                Tue, 05 Feb 2019   Prob (F-statistic):               0.00\n",
    "    Time:                        13:53:10   Log-Likelihood:                -19146.\n",
    "    No. Observations:                6697   AIC:                         3.831e+04\n",
    "    Df Residuals:                    6686   BIC:                         3.839e+04\n",
    "    Df Model:                          10                                         \n",
    "    Covariance Type:            nonrobust                                         \n",
    "    ==============================================================================\n",
    "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
    "    ------------------------------------------------------------------------------\n",
    "    const      -1.082e+04   1100.284     -9.835      0.000    -1.3e+04   -8663.911\n",
    "    AT            -2.4196      0.101    -24.041      0.000      -2.617      -2.222\n",
    "    V             -0.4245      0.031    -13.599      0.000      -0.486      -0.363\n",
    "    AP            21.8406      2.175     10.041      0.000      17.577      26.105\n",
    "    RH             5.8417      0.770      7.586      0.000       4.332       7.351\n",
    "    AT**2          0.0200      0.002      8.876      0.000       0.016       0.024\n",
    "    AT*V           0.0063      0.001      4.410      0.000       0.003       0.009\n",
    "    AT*RH         -0.0071      0.001     -8.037      0.000      -0.009      -0.005\n",
    "    AP**2         -0.0105      0.001     -9.784      0.000      -0.013      -0.008\n",
    "    AP*RH         -0.0054      0.001     -7.273      0.000      -0.007      -0.004\n",
    "    RH**2         -0.0024      0.000     -8.563      0.000      -0.003      -0.002\n",
    "    ==============================================================================\n",
    "    Omnibus:                     1025.730   Durbin-Watson:                   2.000\n",
    "    Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6609.773\n",
    "    Skew:                          -0.570   Prob(JB):                         0.00\n",
    "    Kurtosis:                       7.732   Cond. No.                     2.19e+10\n",
    "    ==============================================================================\n",
    "    \n",
    "    Warnings:\n",
    "    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "    [2] The condition number is large, 2.19e+10. This might indicate that there are\n",
    "    strong multicollinearity or other numerical problems.\n",
    "\n",
    "    MSE TRAINING:  17.84446519859421\n",
    "    MSE TEST:  19.016242392474595\n",
    "\n",
    "    \n",
    "    i)\n",
    "       Raw data: \n",
    "       Optimal K : 5\n",
    "![png](output_19_0.png)\n",
    "\n",
    "\n",
    "       Normalized Data: \n",
    "       Optimal K : 4\n",
    "\n",
    "![png](output_20_0.png)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    j)\n",
    "    By comparing the test error among errors in KNN regression model for raw data and normalized data,\n",
    "    and erros in linear regression model, found that the smallest test error is provided by the knn \n",
    "    regression model which fit with the Raw Data. The test error is 0.0479398815412072.\n",
    "\n",
    "    2:\n",
<<<<<<< HEAD
    "    a) The flexible statistical learning method will be better. Since the sample size is extremely and the number of predictors is small, we don't need to worry about the overfitting by using a flexible method in this situation.\n",
=======
    "    a) The flexible statistical learning method will be better. Since the sample size is extremely large and the number\n",
    "    of predictors is small, we don't need to worry about the overfitting by using a flexible method in this situation.\n",
>>>>>>> 81a8873e803c4c883137a66e77a68a921962bb93
    "    \n",
    "    b) The inflxible statistical learning method will be better. Because the smaple size is small that the number of predictors is extremely large, by using a flexible method, the model may result with having not enough sample to estimate the coeffecients for each predictor. Thus, it seems better to use an inflexible method.\n",
    "    \n",
    "    c) The flexible statiscical learning method works better. Because the relationship between predictors are not linear, we need to use interaction terms and higher degree of the polynomial features to make the regression flexible .\n",
    "    \n",
    "    d) A flexible statistical learning method works better. The variance of the error terms is large means that some of effective features are not explained by the model, so we need to use a flexible method to minimize the varience of the error terms.\n",
    "    \n",
    "    \n",
    "    3:\n",
    "    a)\n",
    "        Obs 1: 3.0\n",
    "        Obs 2: 2.0\n",
    "        Obs 3: 3.1622776601683795\n",
    "        Obs 4: 2.23606797749979\n",
    "        Obs 5: 1.4142135623730951\n",
    "        Obs 6: 1.7320508075688772\n",
    "    b)Green, the nearest point is in class Green\n",
    "    c)Red, the nearest three points have two in class Red.\n",
    "    d)Since the Baye decision boundary is non-linear, we would use smallest k to make the decision highly flexible.\n",
    "    Thus, K=1.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
